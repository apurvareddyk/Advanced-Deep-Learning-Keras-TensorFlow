{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONg+wiMVbNXwNpU6EwMwTv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Part 1d: TensorFlow - Monte Carlo Dropout\n","\n","**Description:**\n","\n","This Colab demonstrates the Monte Carlo Dropout technique in TensorFlow Keras. Unlike standard evaluation where dropout layers are turned off, Monte Carlo Dropout involves keeping the dropout layers active during inference. By performing multiple forward passes with dropout enabled and averaging the predictions, we can obtain not only a prediction but also an estimate of the model's uncertainty."],"metadata":{"id":"4MDjzDiSNEPY"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIBuA0iwM9Ql","executionInfo":{"status":"ok","timestamp":1744330649963,"user_tz":420,"elapsed":50022,"user":{"displayName":"Apurva Karne","userId":"15669434470397290511"}},"outputId":"5e32d8f1-0c95-4092-bc91-c999cb37f807"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Monte Carlo Dropout - Test Accuracy (averaged predictions): 0.9833333333333333\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_digits\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","# Load the digits dataset\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Model with Dropout\n","mc_dropout_model = models.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","mc_dropout_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","mc_dropout_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=0)\n","\n","# Make multiple predictions with dropout enabled\n","num_samples = 100\n","predictions = np.stack([mc_dropout_model(X_test, training=True) for _ in range(num_samples)])\n","mean_prediction = np.mean(predictions, axis=0)\n","\n","# Evaluate the performance based on the average prediction\n","predicted_classes = np.argmax(mean_prediction, axis=1)\n","accuracy = np.mean(predicted_classes == y_test)\n","\n","print(\"\\nMonte Carlo Dropout - Test Accuracy (averaged predictions):\", accuracy)"]},{"cell_type":"markdown","source":["## Results for Part 1d: TensorFlow - Monte Carlo Dropout\n","\n","In this experiment, we explored the Monte Carlo Dropout technique using a simple neural network with a Dropout layer (dropout rate of 0.5) trained on the `digits` dataset. During the evaluation phase, instead of turning off the Dropout layer as is standard, we kept it active (`training=True`) and performed multiple forward passes (100 times) for each test sample. The final prediction for each sample was obtained by averaging the predictions from these multiple passes.\n","\n","The test accuracy achieved using the averaged predictions from Monte Carlo Dropout was:\n","\n","* **Monte Carlo Dropout - Test Accuracy (averaged predictions):** 0.9833\n","\n","**Analysis:**\n","\n","The result indicates that using Monte Carlo Dropout during inference yielded a high test accuracy of 0.9833 on the `digits` dataset.\n","\n","Monte Carlo Dropout serves two primary purposes:\n","\n","1.  **Improved Prediction Robustness:** By averaging multiple predictions with different sets of neurons being randomly dropped out, the final prediction is often more robust and less susceptible to the peculiarities of individual network configurations.\n","2.  **Uncertainty Estimation:** The variance or entropy of the multiple predictions can provide an estimate of the model's uncertainty in its classification. Higher variance or entropy suggests lower confidence in the prediction. While we didn't explicitly calculate uncertainty in this Colab, the process of generating multiple predictions lays the groundwork for doing so.\n","\n","The high accuracy achieved with Monte Carlo Dropout suggests that for this task and model, keeping dropout active during inference can lead to good generalization performance. The slight difference compared to the standard evaluation (which we didn't explicitly run in this Colab for the dropout model but was around 0.9778 in Part 1b) highlights the potential benefits of this technique."],"metadata":{"id":"BAH1NL2uNf_J"}},{"cell_type":"code","source":[],"metadata":{"id":"Vnb2senjNJRN"},"execution_count":null,"outputs":[]}]}