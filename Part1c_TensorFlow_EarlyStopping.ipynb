{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEfZENUltGuUY9tSh57teR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Part 1c: TensorFlow - Early Stopping\n","\n","**Description:**\n","\n","This Colab demonstrates the use of the Early Stopping callback in TensorFlow Keras. Early stopping is a regularization technique that monitors the model's performance on a validation set and stops training when the performance stops improving for a specified number of epochs. This prevents overfitting by halting the training process before the model starts to memorize the training data."],"metadata":{"id":"1k27TJCdM073"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dO8ixs6PMs81","executionInfo":{"status":"ok","timestamp":1744330598121,"user_tz":420,"elapsed":66745,"user":{"displayName":"Apurva Karne","userId":"15669434470397290511"}},"outputId":"cd79923a-9858-4562-cb9b-a6af7f97c3c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation:\n","No Early Stopping - Test Accuracy: 0.9777777791023254\n","Early Stopping - Test Accuracy: 0.9861111044883728\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_digits\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the digits dataset\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# Model without Early Stopping\n","model_no_es = models.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dense(10, activation='softmax')\n","])\n","model_no_es.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history_no_es = model_no_es.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=0)\n","\n","# Model with Early Stopping\n","model_early_stopping = models.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dense(10, activation='softmax')\n","])\n","model_early_stopping.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history_early_stopping = model_early_stopping.fit(\n","    X_train, y_train,\n","    epochs=100,  # Train for more epochs to allow early stopping to activate\n","    validation_data=(X_test, y_test),\n","    callbacks=[early_stopping],\n","    verbose=0\n",")\n","\n","# Evaluate the models\n","print(\"\\nEvaluation:\")\n","print(\"No Early Stopping - Test Accuracy:\", model_no_es.evaluate(X_test, y_test, verbose=0)[1])\n","print(\"Early Stopping - Test Accuracy:\", model_early_stopping.evaluate(X_test, y_test, verbose=0)[1])"]},{"cell_type":"markdown","source":["## Results for Part 1c: TensorFlow - Early Stopping\n","\n","In this experiment, we investigated the impact of using the Early Stopping callback during the training of a simple neural network on the `digits` dataset. We compared a model trained for a fixed number of epochs (100 in this case) with a model that used Early Stopping based on the validation loss. The Early Stopping callback was configured to monitor the validation loss (`val_loss`) with a patience of 10 epochs and to restore the best weights found during training.\n","\n","The test accuracies achieved by each model are as follows:\n","\n","* **No Early Stopping - Test Accuracy:** 0.9778\n","* **Early Stopping - Test Accuracy:** 0.9861\n","\n","**Analysis:**\n","\n","The results clearly demonstrate the benefit of using Early Stopping in this scenario:\n","\n","* The model trained with **Early Stopping** achieved a higher test accuracy of 0.9861 compared to the model trained for a fixed number of epochs, which reached 0.9778.\n","\n","This improvement suggests that Early Stopping effectively prevented overfitting by stopping the training process at a point where the model generalized better to the unseen test data. The model trained without Early Stopping might have continued training beyond an optimal point, potentially starting to memorize the training data and thus performing slightly worse on the test set.\n","\n","The use of `restore_best_weights=True` in the Early Stopping callback is crucial as it ensures that the model's weights are set back to the values that yielded the best performance on the validation set, rather than the weights at the very last epoch of training (which might have been suboptimal)."],"metadata":{"id":"klQUzabANTtN"}},{"cell_type":"code","source":[],"metadata":{"id":"X0jWDgCAM4vh"},"execution_count":null,"outputs":[]}]}