{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhqWXbPzWEjfCU2viLr0G7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Part 1b: TensorFlow - Dropout Regularization\n","\n","**Description:**\n","\n","This Colab illustrates the use of the Dropout regularization technique in TensorFlow Keras. Dropout is a probabilistic method where randomly selected neurons are ignored during training. This helps to prevent overfitting by reducing the interdependence between neurons and encouraging the network to learn more robust features.\n","\n","We will build a simple neural network with a Dropout layer and compare its performance to a network without dropout on the `digits` dataset."],"metadata":{"id":"H4gpW31ZLEca"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGS_xRxuLCWk","executionInfo":{"status":"ok","timestamp":1744330151672,"user_tz":420,"elapsed":37132,"user":{"displayName":"Apurva Karne","userId":"15669434470397290511"}},"outputId":"1be064f3-6877-4c3a-f2f1-4c64da3d8230"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation:\n","No Dropout - Test Accuracy: 0.9750000238418579\n","Dropout Regularization - Test Accuracy: 0.9777777791023254\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_digits\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the digits dataset\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Scale the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Model without Dropout\n","model_no_dropout = models.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dense(10, activation='softmax')\n","])\n","model_no_dropout.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history_no_dropout = model_no_dropout.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=0)\n","\n","# Model with Dropout\n","model_dropout = models.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dropout(0.5),  # Dropout layer with a 50% dropout rate\n","    layers.Dense(10, activation='softmax')\n","])\n","model_dropout.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","history_dropout = model_dropout.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=0)\n","\n","# Evaluate the models\n","print(\"\\nEvaluation:\")\n","print(\"No Dropout - Test Accuracy:\", model_no_dropout.evaluate(X_test, y_test, verbose=0)[1])\n","print(\"Dropout Regularization - Test Accuracy:\", model_dropout.evaluate(X_test, y_test, verbose=0)[1])"]},{"cell_type":"markdown","source":["## Results for Part 1b: TensorFlow - Dropout Regularization\n","\n","In this experiment, we compared the performance of a simple neural network model trained with and without Dropout regularization on the `digits` dataset. The Dropout layer was added after the first dense layer with a dropout rate of 0.5.\n","\n","The test accuracies achieved by each model are as follows:\n","\n","* **No Dropout - Test Accuracy:** 0.9750\n","* **Dropout Regularization - Test Accuracy:** 0.9778\n","\n","**Analysis:**\n","\n","The results suggest that in this specific scenario:\n","\n","* The model with **Dropout regularization** achieved a slightly higher test accuracy (0.9778) compared to the model without dropout (0.9750).\n","\n","Dropout is intended to prevent overfitting by reducing the co-adaptation of neurons. While the improvement in this case is small, it indicates that dropout might be helping the model generalize slightly better to the unseen test data. The effectiveness of dropout can depend on factors like the network depth, the number of neurons, and the dropout rate. Further tuning of the dropout rate could potentially lead to more significant improvements.\n","\n"],"metadata":{"id":"g-nj_IobMTch"}},{"cell_type":"code","source":[],"metadata":{"id":"vALf-iXhLUVc"},"execution_count":null,"outputs":[]}]}